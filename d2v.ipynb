{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the dependencies\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from gensim.models.doc2vec import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import training data from csv\n",
    "df= pd.read_csv(\"final_dataset.csv\")\n",
    "data = df[\"Responses\"].tolist()\n",
    "#print(data)\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(str(_d).lower()), tags=[str(i)]) for i, _d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_epochs:100\n",
      "    act score  prd_score\n",
      "0          20  18.062727\n",
      "1          15  18.094068\n",
      "2           0  17.819857\n",
      "3          25  17.215531\n",
      "4          30  17.808391\n",
      "5          15  17.694807\n",
      "6          20  18.270608\n",
      "7          25  17.774553\n",
      "8          30  18.084802\n",
      "9          20  17.045041\n",
      "10         25  17.991106\n",
      "11         15  17.960514\n",
      "12         20  17.431810\n",
      "13         15  18.037452\n",
      "14          5  17.586563\n",
      "15         20  17.405878\n",
      "16         25  17.952830\n",
      "17          0  18.049886\n",
      "18         20  18.163231\n",
      "19         30  17.420772\n",
      "20         15  16.849757\n",
      "21         20  18.045673\n",
      "22         10  16.623462\n",
      "23         15  17.829019\n",
      "24         10  17.959496\n",
      "25         15  16.791408\n",
      "26         20  15.808602\n",
      "27          5  17.813835\n",
      "28         20  18.047356\n",
      "29         10  18.198469\n",
      "..        ...        ...\n",
      "70         25  17.279722\n",
      "71         20  18.070663\n",
      "72          5  18.051421\n",
      "73          5  17.861719\n",
      "74         30  18.010212\n",
      "75         10  17.764363\n",
      "76         15  17.492229\n",
      "77         25  17.908849\n",
      "78         10  17.493732\n",
      "79         15  17.440173\n",
      "80         20  17.368283\n",
      "81          0  16.982868\n",
      "82         20  17.698566\n",
      "83         25  17.556115\n",
      "84          0  15.184181\n",
      "85         15  16.697913\n",
      "86         30  18.123332\n",
      "87         25  17.905681\n",
      "88         15  16.437216\n",
      "89         25  17.835192\n",
      "90         25  18.077867\n",
      "91         20  14.144161\n",
      "92          0  17.491856\n",
      "93         10  17.845367\n",
      "94         20  17.910060\n",
      "95         15  17.444699\n",
      "96         15  17.843045\n",
      "97         15  18.009160\n",
      "98         25  17.808678\n",
      "99         15  15.818003\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "max_epochs = [100]\n",
    "vec_size = 10000\n",
    "alpha = 0.025\n",
    "\n",
    "for k in max_epochs:\n",
    "    print(\"max_epochs:\" + str(k))\n",
    "          \n",
    "    model = Doc2Vec(vector_size=vec_size,\n",
    "                    alpha=alpha, \n",
    "                    min_alpha=0.00025,\n",
    "                    min_count=1,\n",
    "                    dm =1)\n",
    "\n",
    "    model.build_vocab(tagged_data)\n",
    "\n",
    "    for epoch in range(k):\n",
    "        #print('iteration {0}'.format(epoch))\n",
    "        model.train(tagged_data,\n",
    "                    total_examples=model.corpus_count,\n",
    "                    epochs=model.epochs)\n",
    "        # decrease the learning rate\n",
    "        model.alpha -= 0.0002\n",
    "        # fix the learning rate, no decay\n",
    "        model.min_alpha = model.alpha\n",
    "\n",
    "    model.save(\"d2v.model\")\n",
    "\n",
    "    model= Doc2Vec.load(\"d2v.model\")\n",
    "    #to find the vector of a document which is not in training data\n",
    "    f = open(\"reference_answer.txt\", \"r+\")\n",
    "    refAnswer = f.readline()\n",
    "    f.close()\n",
    "\n",
    "    ref_answer_data = word_tokenize(refAnswer.lower())\n",
    "    ref_answer_vector = model.infer_vector(ref_answer_data)\n",
    "    #print(\"V1_infer\", ref_answer_vector)\n",
    "\n",
    "    cos_sim = []\n",
    "    for i in df[\"Responses\"]:\n",
    "        response_data = word_tokenize(str(i).lower())\n",
    "        response_vector = model.infer_vector(response_data)\n",
    "        dot = np.dot(response_vector, ref_answer_vector)\n",
    "        norma = np.linalg.norm(response_vector)\n",
    "        normb = np.linalg.norm(ref_answer_vector)\n",
    "        cos = dot / (norma * normb)\n",
    "        cos_sim.append(cos)\n",
    "    df[\"cos_sim\"] = cos_sim\n",
    "\n",
    "    X = df['cos_sim'].values\n",
    "    y = df['Final Score'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)\n",
    "\n",
    "    # Fitting Simple Linear Regression to the Training set\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train.reshape(-1, 1), y_train.reshape(-1, 1))\n",
    "    \n",
    "    y_pred = regressor.predict(X_test.reshape(-1, 1))\n",
    "    \n",
    "    df1 = pd.DataFrame(y_test.reshape(-1, 1), columns = ['act score'])\n",
    "    df1[\"prd_score\"] = y_pred\n",
    "    print(df1.head(100))\n",
    "    \n",
    "    \"\"\"# Visualizing the Training set results\n",
    "    viz_train = plt\n",
    "    viz_train.scatter(X_train.reshape(-1, 1), y_train.reshape(-1, 1), color='red')\n",
    "    viz_train.plot(X_train.reshape(-1, 1), regressor.predict(X_train.reshape(-1, 1)), color='blue')\n",
    "    viz_train.title('Original score VS Cosin similarity (Training set)')\n",
    "    viz_train.xlabel('Cosin similarity')\n",
    "    viz_train.ylabel('Original score')\n",
    "    viz_train.show()\n",
    "\n",
    "    # Visualizing the Test set results\n",
    "    viz_test = plt\n",
    "    viz_test.scatter(X_test.reshape(-1, 1), y_test.reshape(-1, 1), color='red')\n",
    "    viz_test.plot(X_train.reshape(-1, 1), regressor.predict(X_train.reshape(-1, 1)), color='blue')\n",
    "    viz_test.title('Original score VS Cosin similarity (Test set)')\n",
    "    viz_test.xlabel('Cosin similarity')\n",
    "    viz_test.ylabel('Original score')\n",
    "    viz_test.show()\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
